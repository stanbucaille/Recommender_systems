{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVF3pGa35Az-"
   },
   "source": [
    "# Recommender Systems with Implicit Feedback\n",
    "\n",
    "The objective of this lab is to build a recommender system using implicit feedback only (users expressing interest for some items). We use the [MovieLens](https://grouplens.org/datasets/movielens/) dataset, filtering user-movie pairs with positive rating (at least 4).\n",
    "\n",
    "The recommender system is based on a neural network trained with the [triplet loss](https://en.wikipedia.org/wiki/Triplet_loss).\n",
    "\n",
    "This lab is inspired by [that](https://github.com/m2dsupsdlclass/lectures-labs/blob/master/labs/03_neural_recsys/Implicit_Feedback_Recsys_with_the_triplet_loss_rendered.ipynb) proposed by Olivier Griesel and Charles Ollion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1863,
     "status": "ok",
     "timestamp": 1576524912882,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "mi5Map_q5Az_",
    "outputId": "0434e570-719b-4e48-ac1d-611659e0b7c5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import scipy.stats as stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1863,
     "status": "ok",
     "timestamp": 1576524912882,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "mi5Map_q5Az_",
    "outputId": "0434e570-719b-4e48-ac1d-611659e0b7c5"
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, Dense\n",
    "from keras.layers import Lambda, Dot\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import dot, concatenate\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVF3pGa35Az-"
   },
   "source": [
    "## Data loading\n",
    "\n",
    "We use the [MovieLens 1M](https://grouplens.org/datasets/movielens/1m/) dataset (1M ratings). It might be necessary to adapt the architecture of the neural nets and the hyperparameters used to train them to work on larger datasets like [MovieLens 10M](https://grouplens.org/datasets/movielens/10m/) or [Yahoo Songs](https://webscope.sandbox.yahoo.com/catalog.php?datatype=r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1863,
     "status": "ok",
     "timestamp": 1576524912882,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "mi5Map_q5Az_",
    "outputId": "0434e570-719b-4e48-ac1d-611659e0b7c5"
   },
   "outputs": [],
   "source": [
    "dataset = \"ml-1m\"\n",
    "filename = dataset + \".zip\"\n",
    "url = \"http://files.grouplens.org/datasets/movielens/\" + filename\n",
    "\n",
    "if not op.exists(filename):\n",
    "    print('Downloading %s to %s...' % (url, dataset))\n",
    "    urlretrieve(url, filename)\n",
    "\n",
    "if not op.exists(dataset):\n",
    "    print('Extracting %s to %s...' % (filename, dataset))\n",
    "    ZipFile(filename).extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1022,
     "status": "ok",
     "timestamp": 1576524919285,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "jz1pzMNJ5A0H",
    "outputId": "9126a453-7ffb-4194-de72-d226a72691d1"
   },
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(op.join(dataset, 'ratings.dat'), sep='::', \n",
    "                        names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"], engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     1193       5  978300760\n",
       "1        1      661       3  978302109\n",
       "2        1      914       3  978301968\n",
       "3        1     3408       4  978300275\n",
       "4        1     2355       5  978824291"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynio8kDF5A0K"
   },
   "outputs": [],
   "source": [
    "df_items = pd.read_csv(op.join(dataset, 'movies.dat'), sep='::',\n",
    "                    names=['item_id', 'title', 'category'], engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3878</td>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3879</td>\n",
       "      <td>3949</td>\n",
       "      <td>Requiem for a Dream (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>3950</td>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3881</td>\n",
       "      <td>3951</td>\n",
       "      <td>Two Family House (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3882</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                               title  \\\n",
       "0           1                    Toy Story (1995)   \n",
       "1           2                      Jumanji (1995)   \n",
       "2           3             Grumpier Old Men (1995)   \n",
       "3           4            Waiting to Exhale (1995)   \n",
       "4           5  Father of the Bride Part II (1995)   \n",
       "...       ...                                 ...   \n",
       "3878     3948             Meet the Parents (2000)   \n",
       "3879     3949          Requiem for a Dream (2000)   \n",
       "3880     3950                    Tigerland (2000)   \n",
       "3881     3951             Two Family House (2000)   \n",
       "3882     3952               Contender, The (2000)   \n",
       "\n",
       "                          category  \n",
       "0      Animation|Children's|Comedy  \n",
       "1     Adventure|Children's|Fantasy  \n",
       "2                   Comedy|Romance  \n",
       "3                     Comedy|Drama  \n",
       "4                           Comedy  \n",
       "...                            ...  \n",
       "3878                        Comedy  \n",
       "3879                         Drama  \n",
       "3880                         Drama  \n",
       "3881                         Drama  \n",
       "3882                Drama|Thriller  \n",
       "\n",
       "[3883 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some titles are missing!\n",
    "df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids = np.array(df_items['item_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = np.array(df_items['title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.array(df_items['category'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first represent data as a sparse matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 to start indices at 0\n",
    "row = np.array(df_ratings['user_id'].values) - 1\n",
    "col = np.array(df_ratings['item_id'].values) - 1\n",
    "data = df_ratings['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mat = sparse.csr_matrix((data, (row, col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3952 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1000209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only movies with a title\n",
    "rating_mat = rating_mat[:,item_ids - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3883 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1000209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_items = rating_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_items == len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only movies with at least one rating\n",
    "total_ratings = rating_mat.T.dot(np.ones(n_users))\n",
    "index = np.argwhere(total_ratings).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mat = rating_mat[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1000209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_items = rating_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categories[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_items == len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=1000209, minmax=(1, 5), mean=3.581564453029317, variance=1.2479165329363373, skewness=-0.5536090572523492, kurtosis=-0.3519750423968597)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall ratings \n",
    "stats.describe(rating_mat.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Views (binary matrix)\n",
    "view_mat = rating_mat.copy()\n",
    "view_mat.data = np.ones_like(view_mat.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=6040, minmax=(20.0, 2314.0), mean=165.5975165562914, variance=37151.41721522576, skewness=2.743966112411747, kurtosis=11.1920071429534)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_views = view_mat.dot(np.ones(n_items))\n",
    "stats.describe(user_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=3706, minmax=(1.0, 3428.0), mean=269.88909875876953, variance=147492.74154374897, skewness=2.813796491583702, kurtosis=10.661899563165777)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_views = view_mat.T.dot(np.ones(n_users))\n",
    "stats.describe(item_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=6040, minmax=(1.0153846153846153, 4.962962962962963), mean=3.702704866999724, variance=0.18457513358365776, skewness=-0.5784169868011894, kurtosis=1.0670999843652567)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings\n",
    "user_ratings = rating_mat.dot(np.ones(n_items)) / user_views\n",
    "stats.describe(user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=3706, minmax=(1.0, 5.0), mean=3.2388921779108912, variance=0.45282771122020127, skewness=-0.6257786213568961, kurtosis=0.3246479366504329)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_ratings = rating_mat.T.dot(np.ones(n_users)) /  item_views\n",
    "stats.describe(item_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "17PDqehx5A0U"
   },
   "source": [
    "## Implicit feedback\n",
    "\n",
    "We now filter positive ratings (>= 4) to get implicit feedback, as a binary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uG6zwgYd5A0W"
   },
   "outputs": [],
   "source": [
    "feedback = rating_mat >= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 575281 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only users with at least 20 ratings\n",
    "user_feedback = feedback.dot(np.ones(n_items))\n",
    "index = np.argwhere(user_feedback >= 20).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5180"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = feedback[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5180x3706 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 562800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_items = feedback.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove items with no feedback\n",
    "item_feedback = feedback.T.dot(np.ones(n_users))\n",
    "index = np.argwhere(item_feedback).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3526"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = feedback[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5180x3526 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 562800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categories[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_items = feedback.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=5180, minmax=(20.0, 1435.0), mean=108.64864864864865, variance=11592.10861952897, skewness=2.862125739601998, kurtosis=14.48003819018539)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User feedback\n",
    "user_feedback = feedback.dot(np.ones(n_items))\n",
    "stats.describe(user_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=3526, minmax=(1.0, 2608.0), mean=159.61429381735678, variance=76854.96551477777, skewness=3.558113622862412, kurtosis=16.86943490652283)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item feedback\n",
    "item_feedback = feedback.T.dot(np.ones(n_users))\n",
    "stats.describe(item_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train set / test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep 10 items per user for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feedback = feedback.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_users):\n",
    "    index = np.random.choice(feedback[i].indices, size = 10, replace = False)\n",
    "    train_feedback[i,index] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feedback = feedback - train_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5180x3526 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 51800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10., 10., 10., ..., 10., 10., 10.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feedback.dot(np.ones(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5180x3526 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 562800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null entries \n",
    "train_feedback = feedback - test_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5180x3526 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 511000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=5180, minmax=(10.0, 1425.0), mean=98.64864864864865, variance=11592.10861952897, skewness=2.862125739601998, kurtosis=14.48003819018539)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User feedback in train set\n",
    "train_user_feedback = train_feedback.dot(np.ones(n_items))\n",
    "stats.describe(train_user_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=3526, minmax=(0.0, 2218.0), mean=144.92342597844583, variance=61176.069595748704, skewness=3.4262272577891633, kurtosis=15.496698957234099)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item feedback in train set\n",
    "train_item_feedback = train_feedback.T.dot(np.ones(n_users))\n",
    "stats.describe(train_item_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8EgmhSW5A0j"
   },
   "source": [
    "## Triplet loss\n",
    "\n",
    "We now build a neural network with the triplet loss. The similarity score between a user and an item is given by the cosine similarity of their respective embeddings. This score will be used to recommend items to any user.\n",
    "\n",
    "Training is achieved by forcing the network to give a higher score to positive items (seen by the user) than to  negative items (not seen by the user). \n",
    "\n",
    "<img src=\"https://perso.telecom-paris.fr/bonald/images/triplet-loss.jpg\" style=\"width: 600px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1989,
     "status": "ok",
     "timestamp": 1576529982401,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "ex1n44u-5A0k",
    "outputId": "30a64535-81f8-471d-b821-1e3a82eae9be"
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    \"\"\"Ignore y_true and return the mean of y_pred\n",
    "    \n",
    "    This is a hack to work-around the design of the Keras API that is\n",
    "    not really suited to train networks with a triplet loss by default.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(y_pred + 0 * y_true)\n",
    "\n",
    "\n",
    "def difference_loss(inputs, margin=.5):\n",
    "    \"\"\"Triplet loss.\n",
    "    \n",
    "    If the inputs are cosine similarities, they range in\n",
    "    (-1, 1) and their difference is in (-2, 2), so a margin of 1 is suitable.\n",
    "\n",
    "    If the input similarities are not normalized, it might be necessary to \n",
    "    tune the margin.\n",
    "    \"\"\"\n",
    "    positive_pair_sim, negative_pair_sim = inputs\n",
    "    return tf.maximum(negative_pair_sim - positive_pair_sim + margin, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1576530293248,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "m8tzPDzm5A0q",
    "outputId": "fc087331-a1d7-4aeb-d81d-3eae97cb7cb7"
   },
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "def build_models(n_users, n_items, latent_dim=64):\n",
    "    \"\"\"Build a triplet model and its companion, the match model\n",
    "    \n",
    "    The triplet model is used to train the weights of the \n",
    "    match model. The triplet model takes 1 user, 1 positive item, \n",
    "    1 negative item and is trained with the triplet loss.\n",
    "    \n",
    "    The match model takes 1 user and 1 item as input and returns\n",
    "    the similarity score.\n",
    "    \"\"\"\n",
    "    # inputs\n",
    "    user_input = Input((1,), name='user_input')\n",
    "    positive_item_input = Input((1,), name='positive_item_input')\n",
    "    negative_item_input = Input((1,), name='negative_item_input')\n",
    "\n",
    "    # embeddings\n",
    "    user_layer = Embedding(n_users, latent_dim, \n",
    "                           name='user_embedding')\n",
    "    item_layer = Embedding(n_items, latent_dim, \n",
    "                           name=\"item_embedding\")\n",
    "\n",
    "    user_embedding = Flatten()(user_layer(user_input))\n",
    "    positive_item_embedding = Flatten()(item_layer(positive_item_input))\n",
    "    negative_item_embedding = Flatten()(item_layer(negative_item_input))\n",
    "\n",
    "    # similarity as cosine similarity between embeddings\n",
    "    positive_similarity = Dot(name=\"positive_similarity\",\n",
    "                              axes=1, normalize=True)(\n",
    "        [user_embedding, positive_item_embedding])\n",
    "    negative_similarity = Dot(name=\"negative_similarity\",\n",
    "                              axes=1, normalize=True)(\n",
    "        [user_embedding, negative_item_embedding])\n",
    "\n",
    "    # triplet loss net, only used for training\n",
    "    triplet_loss = Lambda(difference_loss,\n",
    "                          name='triplet_loss',\n",
    "                          output_shape=(1,))([positive_similarity, negative_similarity])\n",
    "\n",
    "    triplet_model = Model(name='Triplet loss net',inputs=[user_input,\n",
    "                                  positive_item_input,\n",
    "                                  negative_item_input],\n",
    "                          outputs=triplet_loss)\n",
    "    \n",
    "    # match model, used to rank items\n",
    "    match_model = Model(name='Match net', inputs=[user_input, positive_item_input],\n",
    "                        outputs=positive_similarity)\n",
    "    \n",
    "    return triplet_model, match_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1576530293248,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "m8tzPDzm5A0q",
    "outputId": "fc087331-a1d7-4aeb-d81d-3eae97cb7cb7"
   },
   "outputs": [],
   "source": [
    "triplet_model, match_model = build_models(n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1576531037822,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "yRxlyh915A0_",
    "outputId": "d7ef61b9-06d1-4bb0-f0e0-4a7f36371416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Triplet loss net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_item_input (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_item_input (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 64)        331520      user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 64)        225664      positive_item_input[0][0]        \n",
      "                                                                 negative_item_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 64)           0           item_embedding[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "positive_similarity (Dot)       (None, 1)            0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "negative_similarity (Dot)       (None, 1)            0           flatten_4[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "triplet_loss (Lambda)           (None, 1)            0           positive_similarity[0][0]        \n",
      "                                                                 negative_similarity[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 557,184\n",
      "Trainable params: 557,184\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(triplet_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1576531030916,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "2OjcwLz35A06",
    "outputId": "a74a2095-cf8e-4629-ecee-a20b85bffa2f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Match net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_item_input (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 64)        331520      user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 64)        225664      positive_item_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "positive_similarity (Dot)       (None, 1)            0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 557,184\n",
      "Trainable params: 557,184\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(match_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmP50bKQ5A1N"
   },
   "source": [
    "## Metrics\n",
    "\n",
    "We need a metric to assess the quality of the recommander system. Specifically, we would like to check that, for each user, items in the test set tend to get high scores compared to other unseen items (not in the train set). \n",
    "We use the [ROC AUC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) metric:\n",
    "* ROC = Receiver Operating Characteristic = True positive rate (fraction of the test set above the threshold) against False positive rate (fraction not in the test set above the threshold) for various thresholds on the score. \n",
    "* AUC = Area Under Curve\n",
    "\n",
    "Observe that the ROC AUC is between 0 and 1. It can be interpreted as the probability that a random pair of items, one in the test set (positive feedback) and the other not in the test set (no feedback) is correctly ranked by the model, for any given user. There is one ROC AUC metric per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zc3mI_OC5A10"
   },
   "outputs": [],
   "source": [
    "def model_scores(match_model):\n",
    "    \"\"\"Compute the ROC AUC score of each user\"\"\"\n",
    "    scores = []\n",
    "    for i in range(n_users):\n",
    "        # items not in the training set\n",
    "        items_to_rank = np.setdiff1d(np.arange(n_items), train_feedback[i].indices)\n",
    "        \n",
    "        # items in the test set = 1, others = 0\n",
    "        expected = np.in1d(items_to_rank, test_feedback[i].indices)\n",
    "        \n",
    "        # model prediction\n",
    "        repeated_user = np.repeat(i, repeats=len(items_to_rank))\n",
    "        predicted = match_model.predict([repeated_user, items_to_rank], batch_size=4096).ravel()\n",
    "        \n",
    "        # ROC AUC\n",
    "        scores.append(roc_auc_score(expected, predicted))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* What is the expected ROC AUC of a random score function?\n",
    "* Check your guess on the current model (not yet trained)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKMI356I5A15"
   },
   "source": [
    "## Network training\n",
    "\n",
    "Let's now train the network by sampling triplets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Complete the following function that sample triplets.\n",
    "* Train the network and check the ROC AUC.\n",
    "* List the 20 items recommanded by the model (unseen by the user) for the user with the highest and the user with the lowest ROC AUC. <br> How many of these items are in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2bOQ3dy5A16"
   },
   "outputs": [],
   "source": [
    "def sample_triplets():\n",
    "    \"\"\"Sample negatives at random among items not in the train set\"\"\"\n",
    "    \n",
    "    users = []\n",
    "    pos_items = []\n",
    "    neg_items = []\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        items = train_feedback[i].indices\n",
    "        users += list(i * np.ones_like(items))\n",
    "        pos_items += list(items)\n",
    "        # to be modified\n",
    "        neg_items += list(np.zeros_like(items))\n",
    "\n",
    "    return [np.array(users), np.array(pos_items), np.array(neg_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model, match_model = build_models(n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 974
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 148270,
     "status": "ok",
     "timestamp": 1576533042495,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "6gEta9ov5A2B",
    "outputId": "f127a355-2871-41b1-b26b-c0a76bc7cacb"
   },
   "outputs": [],
   "source": [
    "# we plug the identity loss and a fake target variable ignored by\n",
    "# the model to be able to use the Keras API\n",
    "\n",
    "triplet_model.compile(loss=identity_loss, optimizer=\"adam\")\n",
    "fake_y = np.ones_like(train_feedback.data)\n",
    "\n",
    "n_epochs = 3\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    triplets = sample_triplets()\n",
    "    triplet_model.fit(triplets, fake_y, shuffle=True, batch_size=64, epochs=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to assess the quality of the recommendation compared to a simple baseline using the popularity of the items (= number of positive feedback in the train set). Observe that the recommendation is no longer personalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Compare the baseline to the model in terms of ROC AUC.\n",
    "* Compare the 20 first unseen items recommended by the model and by the baseline. You might estimate the number of common items averaged over all  users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To go further\n",
    "\n",
    "* Propose and test a method to get similar items (e.g., the 10 movies the most similar to Fargo).\n",
    "* Propose and test a method to include metadata in the model.\n",
    "* Propose and test a recommender system using graph algorithms (e.g., PageRank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Implicit_recommandation-solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
